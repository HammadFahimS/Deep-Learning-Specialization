# Sequence Models - Week 1 (Deep Learning Specialization)

This repository contains my work for **Week 1** of the Coursera course **Sequence Models** from the Deep Learning Specialization. It includes foundational concepts and implementations for Recurrent Neural Networks (RNNs) and their applications.

## Labs Completed
### 1. **Building a Recurrent Neural Network Step-by-Step**
   - Implemented the forward and backward propagation of a simple RNN.
   - Explored how RNNs process sequential data and maintain hidden states across time steps.

### 2. **Dinosaurus Island - Character-Level Language Model**
   - Built a character-level language model using RNNs to generate dinosaur names.
   - Learned the practical applications of RNNs in text generation tasks.

### 3. **Improvise a Jazz Solo with an LSTM Network**
   - Trained an LSTM model to generate jazz solos.
   - Learned how LSTMs capture long-term dependencies in sequential data, leading to coherent outputs.

## Key Topics Covered
- Recurrent Neural Networks (RNNs): Basic structure and functionality.
- Long Short-Term Memory (LSTM): Handling long-term dependencies.
- Sequential Data Applications: Text generation and music improvisation.

## Repository Structure
```plaintext
.
├── Building_a_Recurrent_Neural_Network_Step_by_Step.ipynb
├── Dinosaurus_Island_Character_level_language_model.ipynb
├── Improvise_a_Jazz_Solo_with_an_LSTM_Network_v4.ipynb
└── README.md

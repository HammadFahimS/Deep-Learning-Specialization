# Sequence Models - Week 2

This repository contains my work for **Week 2** of the Sequence Models course, part of the **Deep Learning Specialization by Andrew Ng**. This week focuses on practical applications of sequence models, including working with word vectors and building simple NLP pipelines.

## Labs Included
1. **Operations on Word Vectors - Debiasing**
   - Explored word embeddings and their role in capturing relationships between words.
   - Implemented techniques to remove bias from word vectors and ensure fairer representations.

2. **Emojify**
   - Built an emoji prediction model using word embeddings and a simple neural network.
   - Worked on processing text inputs and mapping them to corresponding emoji representations.

## Key Topics Covered
- Word embeddings and their applications in NLP.
- Addressing biases in word embeddings to improve fairness.
- Building and training sequence models for real-world NLP tasks.

## Repository Structure
```plaintext
Week2/
├── Operations_on_Word_Vectors_Debiasing.ipynb
├── Emojify.ipynb
└── README.md
